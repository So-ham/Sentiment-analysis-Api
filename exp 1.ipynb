{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0          positive  @VirginAmerica plus you've added commercials t...\n",
       "1          negative  @VirginAmerica it's really aggressive to blast...\n",
       "2          negative  @VirginAmerica and it's a really big bad thing...\n",
       "3          negative  @VirginAmerica seriously would pay $30 a fligh...\n",
       "4          positive  @VirginAmerica yes, nearly every time I fly VX..."
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('airline_sentiment_analysis.csv')\n",
    "data=data[['airline_sentiment','text']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[['airline_sentiment','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11541 entries, 0 to 11540\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   airline_sentiment  11541 non-null  object\n",
      " 1   text               11541 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 180.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@VirginAmerica plus you've added commercials to the experience... tacky.\""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(data['airline_sentiment'],drop_first=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=uint8)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment                                             negative\n",
       "text                 virginamerica its really aggressive to blast o...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']= [x.split(maxsplit=1)[1] for x in data['text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(data['text'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0   15 1383\n",
      "   11  285  205   29   26   16   17  493    1   62  237   10  176  321\n",
      "   53   15   17]\n"
     ]
    }
   ],
   "source": [
    "X = pad_sequences(X)\n",
    "print(X[75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 31, 128)           256000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 197       \n",
      "=================================================================\n",
      "Total params: 510,997\n",
      "Trainable params: 510,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7617, 31) (7617, 1)\n",
      "(1962, 31) (1962, 1)\n",
      "(1962, 31) (1962, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, x_test, Y_train, y_test = train_test_split(X,Y, test_size = 0.34, random_state = 42)\n",
    "X_valid, X_test , Y_valid, Y_test = train_test_split(x_test,y_test, test_size = 0.5, random_state = 42)\n",
    "\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_valid.shape,Y_valid.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpt= ModelCheckpoint('model.h5',monitor='val_accuracy', save_best_only=True, mode='max',verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "239/239 [==============================] - ETA: 0s - loss: 0.3485 - accuracy: 0.8582\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.90826, saving model to model.h5\n",
      "239/239 [==============================] - 17s 71ms/step - loss: 0.3485 - accuracy: 0.8582 - val_loss: 0.2210 - val_accuracy: 0.9083\n",
      "Epoch 2/20\n",
      "239/239 [==============================] - ETA: 0s - loss: 0.1978 - accuracy: 0.9225\n",
      "Epoch 00002: val_accuracy improved from 0.90826 to 0.91947, saving model to model.h5\n",
      "239/239 [==============================] - 16s 68ms/step - loss: 0.1978 - accuracy: 0.9225 - val_loss: 0.1948 - val_accuracy: 0.9195\n",
      "Epoch 3/20\n",
      "238/239 [============================>.] - ETA: 0s - loss: 0.1488 - accuracy: 0.9435 ETA: 1s -\n",
      "Epoch 00003: val_accuracy improved from 0.91947 to 0.91998, saving model to model.h5\n",
      "239/239 [==============================] - 16s 65ms/step - loss: 0.1488 - accuracy: 0.9435 - val_loss: 0.2044 - val_accuracy: 0.9200\n",
      "Epoch 4/20\n",
      "238/239 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.9527\n",
      "Epoch 00004: val_accuracy improved from 0.91998 to 0.92253, saving model to model.h5\n",
      "239/239 [==============================] - 16s 66ms/step - loss: 0.1188 - accuracy: 0.9527 - val_loss: 0.2269 - val_accuracy: 0.9225\n",
      "Epoch 5/20\n",
      "238/239 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 0.9590\n",
      "Epoch 00005: val_accuracy improved from 0.92253 to 0.92559, saving model to model.h5\n",
      "239/239 [==============================] - 16s 67ms/step - loss: 0.1005 - accuracy: 0.9590 - val_loss: 0.2346 - val_accuracy: 0.9256\n",
      "Epoch 6/20\n",
      "238/239 [============================>.] - ETA: 0s - loss: 0.0840 - accuracy: 0.9669\n",
      "Epoch 00006: val_accuracy did not improve from 0.92559\n",
      "239/239 [==============================] - 15s 63ms/step - loss: 0.0840 - accuracy: 0.9669 - val_loss: 0.2657 - val_accuracy: 0.9139\n",
      "Epoch 7/20\n",
      "238/239 [============================>.] - ETA: 0s - loss: 0.0716 - accuracy: 0.9723 ETA: 0s - loss: 0\n",
      "Epoch 00007: val_accuracy did not improve from 0.92559\n",
      "239/239 [==============================] - 15s 63ms/step - loss: 0.0717 - accuracy: 0.9723 - val_loss: 0.3271 - val_accuracy: 0.9072\n",
      "Epoch 8/20\n",
      "238/239 [============================>.] - ETA: 0s - loss: 0.0652 - accuracy: 0.9716\n",
      "Epoch 00008: val_accuracy did not improve from 0.92559\n",
      "239/239 [==============================] - 15s 63ms/step - loss: 0.0652 - accuracy: 0.9716 - val_loss: 0.3383 - val_accuracy: 0.9220\n",
      "Epoch 9/20\n",
      "238/239 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9790\n",
      "Epoch 00009: val_accuracy did not improve from 0.92559\n",
      "239/239 [==============================] - 15s 64ms/step - loss: 0.0538 - accuracy: 0.9790 - val_loss: 0.3376 - val_accuracy: 0.9123\n",
      "Epoch 10/20\n",
      "239/239 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9814\n",
      "Epoch 00010: val_accuracy did not improve from 0.92559\n",
      "239/239 [==============================] - 16s 66ms/step - loss: 0.0482 - accuracy: 0.9814 - val_loss: 0.4145 - val_accuracy: 0.9103\n",
      "Epoch 11/20\n",
      "238/239 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.9827\n",
      "Epoch 00011: val_accuracy did not improve from 0.92559\n",
      "239/239 [==============================] - 15s 65ms/step - loss: 0.0435 - accuracy: 0.9827 - val_loss: 0.4281 - val_accuracy: 0.9088\n",
      "Epoch 12/20\n",
      "238/239 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9835\n",
      "Epoch 00012: val_accuracy did not improve from 0.92559\n",
      "239/239 [==============================] - 16s 68ms/step - loss: 0.0400 - accuracy: 0.9835 - val_loss: 0.4026 - val_accuracy: 0.9123\n",
      "Epoch 13/20\n",
      "238/239 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9863\n",
      "Epoch 00013: val_accuracy did not improve from 0.92559\n",
      "239/239 [==============================] - 16s 66ms/step - loss: 0.0365 - accuracy: 0.9863 - val_loss: 0.4549 - val_accuracy: 0.9128\n",
      "Epoch 14/20\n",
      "238/239 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9911\n",
      "Epoch 00014: val_accuracy did not improve from 0.92559\n",
      "239/239 [==============================] - 15s 64ms/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 0.4979 - val_accuracy: 0.9174\n",
      "Epoch 15/20\n",
      "239/239 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9875\n",
      "Epoch 00015: val_accuracy did not improve from 0.92559\n",
      "239/239 [==============================] - 15s 64ms/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.4544 - val_accuracy: 0.9062\n",
      "Epoch 16/20\n",
      "238/239 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9895\n",
      "Epoch 00016: val_accuracy did not improve from 0.92559\n",
      "239/239 [==============================] - 16s 65ms/step - loss: 0.0242 - accuracy: 0.9895 - val_loss: 0.5541 - val_accuracy: 0.9027\n",
      "Epoch 17/20\n",
      "239/239 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9899\n",
      "Epoch 00017: val_accuracy did not improve from 0.92559\n",
      "239/239 [==============================] - 15s 64ms/step - loss: 0.0266 - accuracy: 0.9899 - val_loss: 0.4487 - val_accuracy: 0.9128\n",
      "Epoch 18/20\n",
      "238/239 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9929\n",
      "Epoch 00018: val_accuracy did not improve from 0.92559\n",
      "239/239 [==============================] - 15s 64ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.5406 - val_accuracy: 0.9098\n",
      "Epoch 19/20\n",
      "238/239 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9933\n",
      "Epoch 00019: val_accuracy did not improve from 0.92559\n",
      "239/239 [==============================] - 14s 60ms/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.5219 - val_accuracy: 0.9139\n",
      "Epoch 20/20\n",
      "238/239 [============================>.] - ETA: 0s - loss: 0.0211 - accuracy: 0.9921\n",
      "Epoch 00020: val_accuracy did not improve from 0.92559\n",
      "239/239 [==============================] - 15s 62ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.5584 - val_accuracy: 0.9169\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "history= model.fit(X_train, Y_train,validation_data=(X_valid,Y_valid), epochs = 20, batch_size=batch_size, verbose = 1,callbacks=[checkpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 8ms/step - loss: 0.6003 - accuracy: 0.9052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6002779006958008, 0.9051987528800964]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose = 1, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "twt = ['Such a good service, comfortable']\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twt = pad_sequences(twt, maxlen=31, dtype='int32', value=0)\n",
    "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0][0]\n",
    "if sentiment<0.5:\n",
    "    print(\"negative\")\n",
    "else:\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "twt = ['Worst Service']\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twt = pad_sequences(twt, maxlen=31, dtype='int32', value=0)\n",
    "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0][0]\n",
    "if sentiment<0.5:\n",
    "    print(\"negative\")\n",
    "else:\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyramid\n",
      "  Downloading pyramid-1.10.5-py2.py3-none-any.whl (326 kB)\n",
      "Collecting venusian>=1.0\n",
      "  Downloading venusian-3.0.0-py3-none-any.whl (13 kB)\n",
      "Collecting plaster-pastedeploy\n",
      "  Downloading plaster_pastedeploy-0.7-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting hupper>=1.5\n",
      "  Downloading hupper-1.10.2-py2.py3-none-any.whl (26 kB)\n",
      "Collecting webob>=1.8.3\n",
      "  Downloading WebOb-1.8.6-py2.py3-none-any.whl (114 kB)\n",
      "Collecting zope.deprecation>=3.5.0\n",
      "  Downloading zope.deprecation-4.4.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting translationstring>=0.4\n",
      "  Downloading translationstring-1.4-py2.py3-none-any.whl (15 kB)\n",
      "Collecting plaster\n",
      "  Downloading plaster-1.0-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dasso\\anaconda3\\lib\\site-packages (from pyramid) (49.2.0.post20200714)\n",
      "Requirement already satisfied: zope.interface>=3.8.0 in c:\\users\\dasso\\anaconda3\\lib\\site-packages (from pyramid) (4.7.1)\n",
      "Collecting PasteDeploy>=2.0\n",
      "  Downloading PasteDeploy-2.1.1-py2.py3-none-any.whl (17 kB)\n",
      "Installing collected packages: venusian, plaster, PasteDeploy, plaster-pastedeploy, hupper, webob, zope.deprecation, translationstring, pyramid\n",
      "Successfully installed PasteDeploy-2.1.1 hupper-1.10.2 plaster-1.0 plaster-pastedeploy-0.7 pyramid-1.10.5 translationstring-1.4 venusian-3.0.0 webob-1.8.6 zope.deprecation-4.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-5016f27e512b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mapp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_wsgi_app\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mserver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_server\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0.0.0.0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6543\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserve_forever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\socketserver.py\u001b[0m in \u001b[0;36mserve_forever\u001b[1;34m(self, poll_interval)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__shutdown_request\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                     \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoll_interval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[1;31m# bpo-35017: shutdown() called during select(), exit immediately.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__shutdown_request\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\selectors.py\u001b[0m in \u001b[0;36mselect\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\selectors.py\u001b[0m in \u001b[0;36m_select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'win32'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from wsgiref.simple_server import make_server\n",
    "from pyramid.config import Configurator\n",
    "from pyramid.response import Response\n",
    "\n",
    "def hello_world(request):\n",
    "    return Response('Hello World!')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Configurator() as config:\n",
    "        config.add_route('hello', '/')\n",
    "        config.add_view(hello_world, route_name='hello')\n",
    "        app = config.make_wsgi_app()\n",
    "    server = make_server('0.0.0.0', 6543, app)\n",
    "    server.serve_forever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aniso8601==8.0.0\n",
      "  Downloading aniso8601-8.0.0-py2.py3-none-any.whl (43 kB)\n",
      "Requirement already satisfied: click==7.1.2 in c:\\users\\dasso\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (7.1.2)\n",
      "Requirement already satisfied: Flask==1.1.2 in c:\\users\\dasso\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (1.1.2)\n",
      "Collecting Flask-RESTful==0.3.8\n",
      "  Downloading Flask_RESTful-0.3.8-py2.py3-none-any.whl (25 kB)\n",
      "Collecting Flask-SQLAlchemy==2.4.3\n",
      "  Downloading Flask_SQLAlchemy-2.4.3-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: itsdangerous==1.1.0 in c:\\users\\dasso\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: Jinja2==2.11.2 in c:\\users\\dasso\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (2.11.2)\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in c:\\users\\dasso\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: pytz==2020.1 in c:\\users\\dasso\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (2020.1)\n",
      "Requirement already satisfied: six==1.15.0 in c:\\users\\dasso\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (1.15.0)\n",
      "Requirement already satisfied: SQLAlchemy==1.3.18 in c:\\users\\dasso\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 11)) (1.3.18)\n",
      "Requirement already satisfied: Werkzeug==1.0.1 in c:\\users\\dasso\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 12)) (1.0.1)\n",
      "Installing collected packages: aniso8601, Flask-RESTful, Flask-SQLAlchemy\n",
      "Successfully installed Flask-RESTful-0.3.8 Flask-SQLAlchemy-2.4.3 aniso8601-8.0.0\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model('model.h5')\n",
    "\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s\n",
      "0.020496726\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "twt = ['Such bad service']\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twt = pad_sequences(twt, maxlen=31, dtype='int32', value=0)\n",
    "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0][0]\n",
    "print(sentiment)\n",
    "if sentiment<0.5:\n",
    "    print(\"negative\")\n",
    "else:\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub('[^a-zA-z0-9\\s]','',text)\n",
    "    text = tokenizer.texts_to_sequences([text])\n",
    "    text = pad_sequences(text, maxlen=31, dtype='int32', value=0)\n",
    "    sentiment = model.predict(text,batch_size=1,verbose = 0)[0][0]\n",
    "    print(sentiment)\n",
    "    if sentiment<0.5:\n",
    "        return(\"negative\")\n",
    "    else:\n",
    "        return(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020496726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predict('Such bad service')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'such bad service food'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a='Such bad service ,@food'\n",
    "a=a.lower()\n",
    "a=re.sub('[^a-zA-z0-9\\s]','',a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-7d7416fe9dcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mapp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_wsgi_app\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mserver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_server\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'127.0.0.1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserve_forever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\socketserver.py\u001b[0m in \u001b[0;36mserve_forever\u001b[1;34m(self, poll_interval)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__shutdown_request\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                     \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoll_interval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[1;31m# bpo-35017: shutdown() called during select(), exit immediately.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__shutdown_request\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\selectors.py\u001b[0m in \u001b[0;36mselect\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\selectors.py\u001b[0m in \u001b[0;36m_select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'win32'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from wsgiref.simple_server import make_server\n",
    "from pyramid.config import Configurator\n",
    "from pyramid.response import Response\n",
    "\n",
    "def hello_world(request):\n",
    "    return Response('Hello World')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Configurator() as config:\n",
    "        config.add_route('hello', '/')\n",
    "        config.add_view(hello_world, route_name='hello')\n",
    "        app = config.make_wsgi_app()\n",
    "    server = make_server('127.0.0.1', 5000, app)\n",
    "    server.serve_forever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving on http://DESKTOP-6PBPHLE:6543\n",
      "Incoming request\n",
      "Incoming request\n",
      "Incoming request\n"
     ]
    }
   ],
   "source": [
    "#!pip install waitress\n",
    "from waitress import serve\n",
    "from pyramid.config import Configurator\n",
    "from pyramid.response import Response\n",
    "\n",
    "name='Soham'\n",
    "\n",
    "def hello_world(request):\n",
    "    print('Incoming request')\n",
    "    return Response('<!DOCTYPE html><html lang=\"en\"><head>    <title>Quick Tutorial: {{ name }}</title></head><body><h1>Hi {}</h1></body></html>'.format(name))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Configurator() as config:\n",
    "        config.add_route('hello', '/')\n",
    "        config.add_view(hello_world, route_name='hello')\n",
    "        app = config.make_wsgi_app()\n",
    "    serve(app, host='127.0.0.1', port=6543)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
