{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import os\n",
    "\n",
    "\n",
    "max_words = 2000\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "batch_size=32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadData:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def read_airline(self):\n",
    "        data=pd.read_csv('airline_sentiment_analysis.csv')\n",
    "        data=data[['airline_sentiment','text']]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoding_sentiment():\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    \n",
    "    def encoding(self):\n",
    "        return pd.get_dummies(self.data['airline_sentiment'],drop_first=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing():\n",
    "    def __init__(self):\n",
    "          pass\n",
    "        \n",
    "    def get_lower_regex(self,text):\n",
    "        self.text= self.text.apply(lambda x: x.lower())\n",
    "        self.text = self.text.apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "        return self.text\n",
    "    \n",
    "    def remove_company_tag(self,text):\n",
    "        return pd.Series([x.split(maxsplit=1)[1] for x in self.text])\n",
    "    \n",
    "    def tokenization_padding(self,text):\n",
    "        tokenizer = Tokenizer(num_words=max_words, split=' ')\n",
    "        tokenizer.fit_on_texts(self.text.values)\n",
    "        with open('models/tokenizer.pickle', 'wb') as handle:\n",
    "            pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        self.text=tokenizer.texts_to_sequences(self.text.values)\n",
    "        self.text=pad_sequences(self.text)\n",
    "        return self.text\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Process(Preprocessing):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def dataset_train_preprocess(self,text):\n",
    "        self.text=data['text']\n",
    "        self.text= self.get_lower_regex(self.text)\n",
    "        self.text= self.remove_company_tag(self.text)\n",
    "        self.text= self.tokenization_padding(self.text)\n",
    "        return self.text\n",
    "    \n",
    "    def single_test_preprocess(self,text):\n",
    "        self.text=text\n",
    "        self.text= self.get_lower_regex(self.text)\n",
    "        self.text= self.tokenization_padding(self.text)\n",
    "        return self.text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class architecture():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def lstm_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(max_words, embed_dim,input_length = X.shape[1]))\n",
    "        model.add(SpatialDropout1D(0.4))\n",
    "        model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "        model.add(Dense(1,activation='sigmoid'))\n",
    "        model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Data_Split():\n",
    "    \n",
    "    def __init__(self,text,outcome):\n",
    "        self.features=text\n",
    "        self.outcome=outcome\n",
    "    \n",
    "    def train_split(self):\n",
    "        X_train, x_test, Y_train, y_test = train_test_split(self.features,self.outcome, test_size = 0.34, random_state = 42)\n",
    "        return X_train, x_test, Y_train, y_test\n",
    "    \n",
    "class Valid_Data_Split(Train_Data_Split):\n",
    "    \n",
    "    def valid_test_split(self):\n",
    "        X_test, X_valid, Y_test, Y_valid = train_test_split(self.features,self.outcome, test_size = 0.5, random_state = 42)\n",
    "        return X_test, X_valid, Y_test, Y_valid\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_model:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,model):\n",
    "        checkpt= ModelCheckpoint('models/model.h5',monitor='val_accuracy', save_best_only=True, mode='max',verbose=0)\n",
    "        history= model.fit(X_train, Y_train,validation_data=(X_valid,Y_valid), epochs = 7, batch_size=batch_size, verbose = 0,callbacks=[checkpt])\n",
    "        return history  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Testing:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def testing_metrics(self):\n",
    "        predict=model.predict_classes(X_test,batch_size=32,verbose=0)\n",
    "        print(classification_report(Y_test,predict))\n",
    "        print(confusion_matrix(Y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0          positive  @VirginAmerica plus you've added commercials t...\n",
       "1          negative  @VirginAmerica it's really aggressive to blast...\n",
       "2          negative  @VirginAmerica and it's a really big bad thing...\n",
       "3          negative  @VirginAmerica seriously would pay $30 a fligh...\n",
       "4          positive  @VirginAmerica yes, nearly every time I fly VX..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs('models')\n",
    "data=ReadData().read_airline()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=Encoding_sentiment(data).encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocess_object=Train_Process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,  552,  487, 1246,    1,    2,  166])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=Preprocess_object.dataset_train_preprocess(data)\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=architecture().lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 31, 128)           256000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 197       \n",
      "=================================================================\n",
      "Total params: 510,997\n",
      "Trainable params: 510,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_test_valid, Y_train, y_test_valid= Train_Data_Split(X,Y).train_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_valid, Y_test, Y_valid = Valid_Data_Split(x_test_valid,y_test_valid).valid_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training=Train_model()\n",
    "history=training.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      1582\n",
      "           1       0.76      0.80      0.78       380\n",
      "\n",
      "    accuracy                           0.91      1962\n",
      "   macro avg       0.86      0.87      0.86      1962\n",
      "weighted avg       0.92      0.91      0.91      1962\n",
      "\n",
      "[[1487   95]\n",
      " [  75  305]]\n"
     ]
    }
   ],
   "source": [
    "Test=Testing().testing_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
